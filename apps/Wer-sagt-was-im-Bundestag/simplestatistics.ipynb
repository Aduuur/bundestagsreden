{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import spacy\n",
    "nlp = spacy.load('de') #load spacy model\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/seven/data/git/mpileipzig/penelope/components/\")\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see devStatementGraph and devPaperPipeline for development and documentation\n",
    "def StatementGraphGenerator(inParams):\n",
    "\n",
    "    stm_list = inParams['data']\n",
    "    \n",
    "    if inParams['language'] == 'en':\n",
    "        nlp = spacy.load('en_core_web_sm') #load english spacy model\n",
    "    elif inParams['language'] == 'de':\n",
    "        nlp = spacy.load('de_core_news_sm') #load german spacy model\n",
    "    elif inParams['language'] == 'fr':\n",
    "        nlp = spacy.load('fr_core_news_sm') #load french spacy model\n",
    "    elif inParams['language'] == 'es':\n",
    "        nlp = spacy.load('es_core_news_sm') #load spanish spacy model\n",
    "    elif inParams['language'] == 'pt':\n",
    "        nlp = spacy.load('pt_core_news_sm') #load portuguese spacy model\n",
    "    elif inParams['language'] == 'it':\n",
    "        nlp = spacy.load('it_core_news_sm') #load italian spacy model\n",
    "    elif inParams['language'] == 'nl':\n",
    "        nlp = spacy.load('nl_core_news_sm') #load dutch spacy model\n",
    "    elif inParams['language'] == 'el':\n",
    "        nlp = spacy.load('el_core_news_sm') #load greek spacy model\n",
    "    elif inParams['language'] == 'nb':\n",
    "        nlp = spacy.load('nb_core_news_sm') #load norwegian bokmal spacy model\n",
    "    elif inParams['language'] == 'lt':\n",
    "        nlp = spacy.load('lt_core_news_sm') #load lithuanian spacy model\n",
    "    elif inParams['language'] == 'xx':\n",
    "        nlp = spacy.load('xx_ent_wiki_sm') #load multi-language spacy model\n",
    "\n",
    "    else:\n",
    "        print('ERROR! Language not supported!')\n",
    "        \n",
    "    relevantPOS = inParams['pos']\n",
    "    ignoreLEM = inParams['ignore']\n",
    "    \n",
    "    # 1.2.2 Note: requires spacy and language model to be loaded\n",
    "    print('apply nlp pipeline')\n",
    "    for value in tqdm.tqdm(stm_list):\n",
    "        doc = nlp(value['text'])\n",
    "        value.update({'doc' : doc})\n",
    "    \n",
    "    # 1.2.3\n",
    "    # Data cleaning options\n",
    "    print('filter words')\n",
    "    #relevantPOS = ['NOUN','VERB','ADJ']\n",
    "    #ignoreLEM = ['Herr','Kollege','Dame','Frau','Präsident']\n",
    "    #ignoreLEM = []\n",
    "\n",
    "    stm_list_nlp = []\n",
    "    statements_lemma_list = []\n",
    "    #statements_pos_list = []\n",
    "    for stm in tqdm.tqdm(stm_list):\n",
    "        lemmas = []\n",
    "        pos = []\n",
    "        for token in stm['doc']:\n",
    "            if token.is_punct is not True and token.is_stop is not True and token.pos_ in relevantPOS and token.lemma_ not in ignoreLEM:\n",
    "                lemmas.append(token.lemma_)\n",
    "                pos.append(token.pos_)\n",
    "        stm.update({'lemmata' : lemmas})    \n",
    "        statements_lemma_list.append(lemmas)\n",
    "        #statements_pos_list.append(pos)\n",
    "\n",
    "    # 1.2.4\n",
    "    print('count and order lemmata')\n",
    "    flattened = [val for lemmas in statements_lemma_list for val in lemmas]\n",
    "    lemma_frequency_list = collections.Counter(flattened).most_common()\n",
    "    all_lemmata_list = [ i[0] for i in lemma_frequency_list ]\n",
    "    all_lemmata_count = [ i[1] for i in lemma_frequency_list ]\n",
    "\n",
    "    # remove single items\n",
    "    # 1.2.5\n",
    "    print('remove singles')\n",
    "    all_freq_lemmata_list = [ all_lemmata_list[i] for i,v in enumerate(all_lemmata_list) if (all_lemmata_count[i] > 1) ]\n",
    "    all_freq_lemmata_count = [ all_lemmata_count[i] for i,v in enumerate(all_lemmata_count) if (all_lemmata_count[i] > 1) ]\n",
    "        \n",
    "    all_lemmata_list = all_freq_lemmata_list\n",
    "    all_lemmata_count = all_freq_lemmata_count \n",
    "\n",
    "    # Construct word browsable dict for later use in semantic relatedness computation\n",
    "    wordscounts_dict = {}\n",
    "    for lx,lem in enumerate(all_lemmata_list):\n",
    "        wordscounts_dict.update({ lem : all_lemmata_count[lx] })\n",
    " \n",
    "    # From this file\n",
    "    stmnet_dict = {\n",
    "        'nodes' : [],\n",
    "        'links' : []\n",
    "        }    \n",
    " \n",
    "\n",
    "    for ix,stm in enumerate(stm_list):\n",
    "        if len(stm['lemmata']) > 0:\n",
    "            node_dict = {\n",
    "                'id' : ix+1\n",
    "            }\n",
    "            for ele in stm:\n",
    "                if ele != 'lemmata' and ele != 'doc':\n",
    "                    node_dict.update({ele : stm[ele]})\n",
    "            \n",
    "            mfic = [ lem for lem in all_lemmata_list if (lem in stm['lemmata'] )]\n",
    "            #freqI = collections.Counter(stmI).most_common()\n",
    "            #lemmataI = [ i[0] for i in freqI ]\n",
    "            if len(mfic)>0:\n",
    "                node_dict.update({'mfic' : mfic[0]})\n",
    "            else:\n",
    "                node_dict.update({'mfic' : ' '})\n",
    "    \n",
    "            stmnet_dict['nodes'].append(node_dict)\n",
    "    \n",
    "    \n",
    "    #stmnet_dict['graph']['edges'] = []\n",
    "    for nodeI in tqdm.tqdm(stmnet_dict['nodes']):\n",
    "        stmI = stm_list[ nodeI['id']-1 ]['lemmata']\n",
    "        for nodeJ in stmnet_dict['nodes']:     \n",
    "            if nodeI['id'] < nodeJ['id']:\n",
    "                stmJ = stm_list[ nodeJ['id']-1 ]['lemmata']\n",
    "                overlap = [ lem for lem in set(stmI) if (lem in set(stmJ))]  # set overlap\n",
    "                weight = len(overlap) / (len(stmI)+len(stmJ))\n",
    "                if (len(overlap) > 0):\n",
    "                    edge_dict = {\n",
    "                        'source' : nodeI['id'],\n",
    "                        'target' : nodeJ['id'],\n",
    "                        'weight' : weight\n",
    "                        }\n",
    "                    stmnet_dict['links'].append(edge_dict)\n",
    "    \n",
    "    return stmnet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_query = \"Digitalisierung\"\n",
    "#search_query = \"Klima\"\n",
    "#search_query = \"Sozialismus\"\n",
    "#search_query = \"Kräfte\"\n",
    "\n",
    "#search_query = \"erneuerbar\"\n",
    "#search_query2 = \"wirtschaftlich\"\n",
    "\n",
    "search_query = \"Afrika\"\n",
    "search_query2 = \"Europa\"\n",
    "\n",
    "json = {'search_query':search_query, \n",
    "        'dataset_name':'deu', \n",
    "        'start_date':'2016-1-1', \n",
    "        'end_date':'2021-1-1'}\n",
    "result = requests.post('https://penelope.vub.be/parliament-data/get-speeches', json=json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = []\n",
    "for speech in result.json()[\"speeches\"]:\n",
    "    speeches.append(speech)\n",
    "    #parties.append(speech['party'])\n",
    "    #print(speech['date'])\n",
    "\n",
    "# code to sort list on date \n",
    "speeches.sort(key = lambda x:x['date'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = {'search_query':search_query2, \n",
    "        'dataset_name':'deu', \n",
    "        'start_date':'2016-1-1', \n",
    "        'end_date':'2021-1-1'}\n",
    "result = requests.post('https://penelope.vub.be/parliament-data/get-speeches', json=json)\n",
    "\n",
    "speeches2 = []\n",
    "for speech in result.json()[\"speeches\"]:\n",
    "    speeches2.append(speech)\n",
    "\n",
    "# code to sort list on date \n",
    "speeches2.sort(key = lambda x:x['date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 220 speeches containing _Afrika_ and _Europa_\n"
     ]
    }
   ],
   "source": [
    "jointspeeches=[]\n",
    "for speech in speeches:\n",
    "    if search_query in speech['text'] and search_query2 in speech['text']:\n",
    "        jointspeeches.append(speech)\n",
    "ljoint = len(jointspeeches)\n",
    "print(f\"There are {ljoint} speeches containing _{search_query}_ and _{search_query2}_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_list=[]\n",
    "for speech in tqdm.tqdm(jointspeeches):\n",
    "    doc = nlp(speech[\"text\"])\n",
    "    for sent in doc.sents:\n",
    "        if search_query in sent.text and search_query2 in sent.text:\n",
    "            #print(sent)\n",
    "            stm_dict = {\n",
    "                'name'  : speech[\"name\"],\n",
    "                'party' : speech[\"party\"],\n",
    "                'text'  : sent.text\n",
    "            }\n",
    "            stm_list.append(stm_dict)\n",
    "stm_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:07<00:00, 12.51it/s]\n"
     ]
    }
   ],
   "source": [
    "stm_list=[]\n",
    "for speech in tqdm.tqdm(jointspeeches):\n",
    "    doc = nlp(speech[\"text\"])\n",
    "    if search_query in speech[\"text\"] and search_query2 in speech[\"text\"]:\n",
    "        #print(sent)\n",
    "        stm_dict = {\n",
    "            'name'  : speech[\"name\"],\n",
    "            'party' : speech[\"party\"],\n",
    "            'text'  : speech[\"text\"],\n",
    "            'length' : len(speech['text'])\n",
    "        }\n",
    "        stm_list.append(stm_dict)\n",
    "stm_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Andreas Lenz',\n",
       " 'party': 'CDU/CSU',\n",
       " 'text': 'Sehr geehrte Frau Präsidentin, für die CDU/CSU-Fraktion natürlich, auch wenn ich Sie ungern korrigiere. – Sehr geehrte Damen und Herren! Liebe Kolleginnen und Kollegen! Der deutsche Arbeitsmarkt steht so gut da wie noch nie in der Geschichte der Bundesrepublik. So erreichte die Zahl der Erwerbstätigen im September dieses Jahres mit 44,5 Millionen Menschen in Beschäftigung einen erneuten Höchststand. Das sind 600 000 Menschen mehr als zu diesem Zeitpunkt im letzten Jahr. Dieser wirtschaftliche Erfolg hat auch einen Namen: Das ist die unionsgeführte Bundesregierung. – In Bayern läuft es natürlich noch besser, Kollege Ernst. – Aber gleichzeitig merkt man bei einem geplanten Stellenabbau wie jetzt bei Siemens einmal mehr, dass die gute wirtschaftliche Situation nicht gottgegeben ist. Wir stehen als Wirtschaftsstandort im internationalen Wettbewerb und sind durch unsere Exportorientierung auf die Weltmärkte angewiesen wie kaum ein anderes Land. Das gilt natürlich insbesondere für ein multinationales Unternehmen wie Siemens. So ist die globale Nachfrage nach großen Gasturbinen drastisch gesunken. Auf etwa 110 Turbinen pro Jahr wird sich die globale Nachfrage zukünftig belaufen. Wir haben aber Fertigungskapazitäten für circa 400 Turbinen im Jahr. Es ist hier so, dass es sich um globale Trends handelt, wie es sich auch bei der Entwicklung der erneuerbaren Energien um globale Trends handelt. Darauf muss Siemens natürlich reagieren. Täte Siemens das nicht, wäre das ebenso verantwortungslos. Allerdings gilt es auch, zu betonen, dass gerade Siemens an anderer Stelle vom Umbau der Energieversorgung massiv profitiert, beispielsweise beim Ausbau der Offshorekapazitäten. Das zeigt sich in der Gesamtprofitabilität des Unternehmens. Jetzt muss ich schon auch sagen, dass ich mir die Kommunikation von Siemens hier sicherlich anders gewünscht hätte. Es geht nicht, dass die Arbeitnehmervertretungen vom geplanten Stellenabbau aus den Medien erfahren – einen solchen Stil mag man vielleicht im Umgang von Parteien intern manchmal gewohnt sein, aber das ist kein Umgang auf Augenhöhe. Und das müssen wir als Politik natürlich klar sagen; das müssen wir klar anmahnen. Gerade Siemens als globales Vorzeigeunternehmen hat natürlich auch eine Verpflichtung, seiner sozialen Verantwortung gerecht zu werden. Wertschöpfung durch Wertschätzung – das geht nur miteinander. Verantwortlichkeit sieht an dieser Stelle natürlich anders aus, aber mit Verantwortungslosigkeit kennen Sie sich von der SPD ja sehr gut aus. Deswegen haben Sie ja auch diese Aktuelle Stunde beantragt. Insgesamt ist ein Abbau von 6 900 Stellen geplant, davon die Hälfte in Deutschland im Bereich Power. – An anderer Stelle hat das ja auch die jüngste Vergangenheit gezeigt. Im Bereich Power und Gas geht es konkret um 2 600 Stellen in Deutschland. Dabei sollen die Werke in Görlitz und Leipzig geschlossen werden, aber auch Erfurt, Mülheim, Offenbach, Erlangen und Berlin sind betroffen. Gestern haben hier in Berlin Hunderte Mitarbeiter um das Berliner Gasturbinenwerk in Moabit gegen den Stellenabbau protestiert. Das Motto „Wir umarmen unser Werk“ zeigt die Verbundenheit der Menschen zum Unternehmen. Diese Verbundenheit ist für Siemens eigentlich ein Wert an sich. Es geht um Schicksale, es geht um Existenzen, es geht um Menschen, und das häufig noch dazu in strukturschwachen Gebieten; das haben wir ja gerade schon gehört. Das kann niemanden kaltlassen. Deshalb gilt es, auszuloten, kreativ zu sein, wie man da, wo Aufgaben wegfallen, Ersatz finden kann. Auch die Kanzlerin hat sich eingeschaltet. Auch wenn die Politik letztlich unternehmerische Entscheidungen nicht übernehmen kann und auch nicht soll, geht es darum, an die Verantwortung der Akteure zu erinnern. Das Unternehmen sagt, dass die Maßnahmen sorgfältig, umsichtig und langfristig angelegt sind. Daran werden wir die Unternehmensleitung messen. Die Wirtschaft ist letztlich immer für den Menschen da und nicht anders herum. Der Unternehmensgründer Werner von Siemens meinte: Mit tätigem Eingreifen in die gefürchteten Räder des Schicksals kann man manches Unheil abwenden. – Diesen Geist wünsche ich auch dem aktuellen Unternehmen. Herzlichen Dank. Das Wort hat Thomas Jurk für die SPD-Fraktion. ',\n",
       " 'length': 4243}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties = []\n",
    "\n",
    "dates = []\n",
    "for speech in speeches:\n",
    "    parties.append(speech['party'])\n",
    "    dates.append(speech['date'])\n",
    "    #print(speech['date'],speech['party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Create a column from the datetime variable\n",
    "df['datetime'] = dates\n",
    "# Convert that column into a datetime datatype\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "# Set the datetime column as the index\n",
    "df.index = df['datetime'] \n",
    "# Create a column from the numeric score variable\n",
    "df['party'] = parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22</th>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>DIE LINKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>BÜNDNIS 90/DIE GRÜNEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>BÜNDNIS 90/DIE GRÜNEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime                  party\n",
       "datetime                                    \n",
       "2017-10-24 2017-10-24                CDU/CSU\n",
       "2017-11-21 2017-11-21                CDU/CSU\n",
       "2017-11-21 2017-11-21                CDU/CSU\n",
       "2017-11-21 2017-11-21                CDU/CSU\n",
       "2017-11-22 2017-11-22                CDU/CSU\n",
       "...               ...                    ...\n",
       "2019-11-15 2019-11-15              DIE LINKE\n",
       "2019-11-15 2019-11-15                CDU/CSU\n",
       "2019-11-15 2019-11-15  BÜNDNIS 90/DIE GRÜNEN\n",
       "2019-11-15 2019-11-15                CDU/CSU\n",
       "2019-11-15 2019-11-15  BÜNDNIS 90/DIE GRÜNEN\n",
       "\n",
       "[1040 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data frame by month and item and extract a number of stats from each group\n",
    "total = df.resample('M').agg({'party':'count'})\n",
    "#total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-28</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            party\n",
       "datetime         \n",
       "2017-10-31    1.0\n",
       "2017-11-30    1.0\n",
       "2017-12-31    1.0\n",
       "2018-01-31    1.0\n",
       "2018-02-28    1.0\n",
       "2018-03-31    1.0\n",
       "2018-04-30    1.0\n",
       "2018-05-31    1.0\n",
       "2018-06-30    1.0\n",
       "2018-07-31    1.0\n",
       "2018-08-31    NaN\n",
       "2018-09-30    1.0\n",
       "2018-10-31    1.0\n",
       "2018-11-30    1.0\n",
       "2018-12-31    1.0\n",
       "2019-01-31    1.0\n",
       "2019-02-28    1.0\n",
       "2019-03-31    1.0\n",
       "2019-04-30    1.0\n",
       "2019-05-31    1.0\n",
       "2019-06-30    1.0\n",
       "2019-07-31    NaN\n",
       "2019-08-31    NaN\n",
       "2019-09-30    1.0\n",
       "2019-10-31    1.0\n",
       "2019-11-30    1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CDU/CSU': 400,\n",
       " 'SPD': 205,\n",
       " 'FDP': 167,\n",
       " 'BÜNDNIS 90/DIE GRÜNEN': 92,\n",
       " 'AfD': 87,\n",
       " 'DIE LINKE': 58,\n",
       " 'BÜNDNIS\\xa090/DIE GRÜNEN': 23,\n",
       " 'fraktionslos': 8}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(speeches))\n",
    "partycounts = dict(Counter(parties).most_common())\n",
    "partycounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2018-02-22',\n",
       " 'discussion_title': 'Tagesordnungspunkt 7 2018-02-22',\n",
       " 'id': 'ID191404500',\n",
       " 'name': 'Anja Weisgerber',\n",
       " 'party': 'CDU/CSU',\n",
       " 'period': '19',\n",
       " 'text': 'Sehr geehrte Frau Präsidentin! Werte Kolleginnen und Kollegen! Klimaschutz ist eine große Herausforderung. Er ist wichtig, für manche Inseln im Pazifik ist er eine Überlebensfrage. Aber auch bei uns in Deutschland sind die Auswirkungen des Klimawandels bereits spürbar. Die Entwicklung von Innovationen im Bereich Klimaschutz ist eine Riesenchance für die Wirtschaft. Wir müssen am Ball bleiben. Wir müssen den Wandel gestalten. Wir dürfen ihn nicht verschlafen. Ich war gestern im Umweltministerium, wo der Deutsche Innovationspreis für Klima und Umwelt an mutige Unternehmer verliehen wurde. Auch mir machte diese Veranstaltung Mut, weil ich gesehen habe, mit welcher Kraft und mit welcher Überzeugung die Unternehmer bei der Sache sind. Es wurden tolle Projekte vorgestellt. Zum Beispiel kann Papier aus Gras hergestellt werden, um die Ressource Holz als wertvollen CO 2 -Speicher zu schonen. Ein weiteres Projekt war eine energiesparende Maschine zur Stoffherstellung, die gleichzeitig spinnt und strickt. Sie sehen: Es gibt eine Menge Innovationen durch mutige mittelständische Unternehmer, wodurch Arbeitsplätze geschaffen und auch erhalten werden können. Im ausverhandelten Koalitionsvertrag haben wir ganz klar festgehalten, dass wir uns zu unseren nationalen, europäischen und internationalen Klimazielen bekennen, und zwar in allen Sektoren. Dafür habe ich mich als Klimapolitikerin persönlich eingesetzt. Damit zeigen wir: Wir nehmen unsere klimapolitische Verantwortung wahr, in Deutschland und in der Welt. Für uns ist aber auch wichtig, wie wir dieses Ziel erreichen. Das wollen wir durch Anreize statt Zwang und durch Technologieoffenheit bewerkstelligen. Wir wollen auch sicherstellen, dass unsere Wirtschaft als Basis unseres Wohlstands international wettbewerbsfähig bleibt. Außerdem soll die Energieversorgungssicherheit weiterhin gewährleistet werden. Es liegt eine Studie der deutschen Industrie vor, die sich damit befasst hat, wie wir das langfristige Klimaziel bezogen auf 2050 erreichen wollen. Die Studie besagt: Das wird schwierig, aber es kann funktionieren. Und auch die Wirtschaft sagt: Die Wirtschaft kann Wandel. Sie hat es bei der Industrialisierung bewiesen. Jetzt nimmt sie die Herausforderungen der Digitalisierung an, Stichwort Industrie 4.0. Die Wirtschaft kann auch Klimaschutz, wenn die Politik verlässliche Rahmenbedingungen schafft und Anreize zum Beispiel für effiziente Umwelttechnologien setzt. Und genau das machen wir, meine Damen und Herren. Wenn Sie, die Antragsteller, deren Vorlagen wir heute beraten, den ausgehandelten Koalitionsvertrag aufmerksam lesen, dann werden Sie feststellen, dass viele Ihrer Punkte bereits enthalten sind, zum Beispiel die Forderung nach einer konsequenten Energieeffizienzpolitik. Es gibt bereits den Nationalen Aktionsplan Energieeffizienz, den wir weiterentwickeln werden. Außerdem wollen wir eine ambitionierte, sektorübergreifende Energieeffizienzstrategie unter dem Leitprinzip „Efficiency first“ installieren. Wir haben uns das ehrgeizige Ziel gesetzt, eine Halbierung des Energieverbrauchs bis 2050 zu schaffen. Im Koalitionsvertrag ist vorgesehen, bis 2030 einen Anteil an erneuerbaren Energien von 65 Prozent zu erreichen. Ebenso haben wir verankert – ich muss ganz ehrlich sagen: endlich –, die energetische Gebäudesanierung steuerlich zu fördern. In vielen Reden an diesem Rednerpult habe ich gefordert, dass wir dieses Klimaschutzinstrument nutzen. Meine Damen und Herren, ich setze darauf, dass nun auch die Grünen in den Bundesländern für dieses Instrument werben; denn in den Jamaika-Sondierungen war die Einführung dieses Instruments Konsens. Damit bin ich beim Thema: Wie sollen diese Instrumente ausgestaltet sein? Wie soll dieses Steuerungsinstrument ausgestaltet sein? Wir setzen auf Anreize statt auf Zwang. Unser Vorschlag sieht ein Wahlrecht des Antragstellers vor: Zuschussförderung oder Reduzierung des zu versteuernden Einkommens. Damit erreichen wir einen möglichst großen Personenkreis. Daneben wollen wir das CO 2 -Gebäudesanierungsprogramm fortführen und damit den Austausch alter, ineffizienter Heizungen fördern. Ferner wollen wir eine Kommission einsetzen, die auf Basis und in Vernetzung mit dem laufenden Prozess zur Umsetzung des Klimaschutzplans bis Ende des Jahres Maßnahmen vorschlagen soll, wie die Lücke zur Erreichung des Klimaziels 2020 so schnell wie möglich reduziert werden kann und im Energiesektor das 2030-Ziel erreicht werden kann. Dazu zählt auch die schrittweise Reduzierung und Beendigung der Kohleverstromung. Das Abschlussdatum für die Kohleverstromung soll ebenfalls durch diese Kommission festgelegt werden. Hört! Hört! Meine Damen und Herren, das geht sogar über das hinaus, was am Ende der Jamaika-Sondierungen ausverhandelt war. In den Jamaika-Verhandlungen lag der Fokus – Herr Dr. Köhler hat es bereits erwähnt – auf dem überhasteten, schnellen Stilllegen, auf der Reduzierung der Kapazität der Kohleverstromung um 7 Gigawatt vor 2020, und zwar ohne Rücksicht auf die Arbeitsplätze. Auch wir wollen die schrittweise Reduzierung der Kohleverstromung; aber wir wollen dabei die Energieversorgung weiterhin sicherstellen. Wir wollen, dass Energie für Verbraucher und Wirtschaft bezahlbar bleibt. Das ist ganz wichtig. Ich habe das Gefühl, das wird von den Grünen öfter ausgeblendet. Außerdem wollen wir nicht, dass es in den betroffenen Regionen zu Strukturbrüchen kommt. Sie sehen: Wir reden nicht nur, sondern wir handeln auch, aber durchdacht und mit Weitsicht. Zur Globalen Allianz für den Kohleausstieg, die in einem Antrag erwähnt wird: Gefordert wird, dass Deutschland dieser Allianz beitritt. Ich habe mir die Mühe gemacht, mir den Energiemix der teilnehmenden Staaten anzusehen. Man muss sich da ehrlich machen. Wie ist das in Frankreich? Dort stammen nur 3 bis 4 Prozent der Stromproduktion aus der Kohle, und Frankreich will von dem Ziel abrücken, den Strom aus Kernenergie bis 2025 auf 50 Prozent zu reduzieren. Kanada investiert mehr als 25 Milliarden in Atomreaktoren, damit sie für weitere 25 bis 30 Jahre laufen. Großbritannien will aus der Kohleverstromung aussteigen, gleichzeitig aber den Anteil des Stroms aus Kernenergie deutlich steigern. Wir wollen beides: Wir wollen die Kohleverstromung reduzieren und den Ausstieg aus der Kernenergienutzung weiter gestalten. Keiner behauptet, dass das leicht ist. Dennoch gehen wir diesen Weg voller Überzeugung für unsere Kinder, für unsere Enkel und für die Menschen, die darauf setzen, dass die Politik die Weichen richtig stellt und durch Innovationen im Umweltbereich Arbeitsplätze erhalten und geschaffen werden. Vielen Dank. Vielen Dank, Dr. Weisgerber. – Nächste Rednerin: Bundesministerin Dr. Barbara Hendricks für die Bundesregierung. '}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 851/851 [00:57<00:00, 14.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm_list=[]\n",
    "for speech in tqdm.tqdm(speeches):\n",
    "    doc = nlp(speech[\"text\"])\n",
    "    for sent in doc.sents:\n",
    "        if search_query in sent.text:\n",
    "            #print(sent)\n",
    "            stm_dict = {\n",
    "                'name'  : speech[\"name\"],\n",
    "                'party' : speech[\"party\"],\n",
    "                'text'  : sent.text\n",
    "            }\n",
    "            stm_list.append(stm_dict)\n",
    "    \n",
    "len(stm_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ele in stm_list:\n",
    "#    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [00:00<00:00, 116.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply nlp pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 127.44it/s]\n",
      "100%|██████████| 80/80 [00:00<00:00, 60699.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 10056.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter words\n",
      "count and order lemmata\n",
      "remove singles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inParams = {\n",
    "    'data': stm_list,\n",
    "    'language' : \"de\",\n",
    "    #'pos' : ['NOUN','VERB','ADJ'],\n",
    "    'pos' : ['NOUN'],\n",
    "    'ignore' : [search_query,search_query2]\n",
    "}\n",
    "\n",
    "graph = StatementGraphGenerator(inParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(len(graph['links']),\n",
    "len(graph['nodes']))\n",
    "\n",
    "weights=[]\n",
    "for link in graph['links']:\n",
    "    weights.append(link['weight'])\n",
    "\n",
    "plt.hist(weights, bins=25)\n",
    "plt.title(\"Distribution of Weights\")\n",
    "plt.xlabel(\"Wert\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.show()\n",
    "#print(graph['nodes'])\n",
    "#graph['links']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 79\n"
     ]
    }
   ],
   "source": [
    "newlinks = []\n",
    "for link in graph['links']:\n",
    "    if link['weight'] > 0.07:\n",
    "        newlinks.append(link)\n",
    "graph['links'] = newlinks    \n",
    "print(len(graph['links']),\n",
    "len(graph['nodes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = {'data':graph, \n",
    "        'nodecoloring':'party', \n",
    "        'nodelabel': 'text', \n",
    "        \"darkmode\": False,\n",
    "        \"edgevisibility\": True,\n",
    "        \"particles\": False\n",
    "       }\n",
    "result = requests.post('https://penelope.vub.be/network-components/visualiser', json=json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"./satzgraph.html\", \"w\") as f:\n",
    "    f.write(result.json()['graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: Das funktioniert irgendwie nicht!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Doc is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-7df2a34d65aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"relevant_pos\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"NOUN\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m        }\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://penelope.vub.be/network-components/statementgraphgenerator'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_body\u001b[0;34m(self, data, files, json)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# provides this natively, but Python 3 gives a Unicode string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'application/json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Doc is not JSON serializable"
     ]
    }
   ],
   "source": [
    "#stm_list =[{'text': 'Das war ein Satz.'},\n",
    "#           {'text': 'Der Satz des Tages ist das.'} \n",
    "#]\n",
    "\n",
    "json = {'data':stm_list, \n",
    "        'language':'de', \n",
    "        'ignore': ['Digitalisierung'], \n",
    "        #\"relevant_pos\": [\"VERB\",\"NOUN\",\"ADJ\"]\n",
    "        \"relevant_pos\": [\"NOUN\"]\n",
    "       }\n",
    "result = requests.post('https://penelope.vub.be/network-components/statementgraphgenerator', json=json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "[{'id': 1, 'mfic': '', 'text': 'Das war ein Satz.'}, {'id': 2, 'mfic': '', 'text': 'Der Satz des Tages ist das.'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = result.json()\n",
    "print(len(graph['links']),\n",
    "len(graph['nodes']))\n",
    "print(graph['nodes'])\n",
    "graph['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

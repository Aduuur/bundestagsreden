{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import re\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import collections\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('de') #load spacy model\n",
    "\n",
    "# for WordClouds \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "with open(\"../../bundestagsreden parser/speeches_20.jsonl\",'r',encoding = \"utf8\") as fp:\n",
    "    data = list(fp)\n",
    "speeches = []\n",
    "for line in data:\n",
    "    speeches.append(json.loads(line))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_for(what, search_terms, speeches):\n",
    "    filtered_speeches = []\n",
    "    if what == 'text':\n",
    "        search_terms_low = []\n",
    "        for st in search_terms:\n",
    "            search_terms_low.append(st.lower())\n",
    "        for speech in speeches:\n",
    "            match = [st in speech[what].lower() for st in search_terms_low]\n",
    "            #if all(st == True for st in match):\n",
    "            if any(st in speech[what] for st in search_terms):\n",
    "                #print(match)\n",
    "            #if ( search_terms in speech[what] ):\n",
    "                filtered_speeches.append(speech)\n",
    "    else:\n",
    "        for speech in speeches:\n",
    "            if ( speech[what].lower() in set(search_terms_low) ):\n",
    "                filtered_speeches.append(speech)\n",
    "        \n",
    "    filtered_speeches.sort(key = lambda x:x['date'])   \n",
    "    return filtered_speeches\n",
    "\n",
    "\n",
    "#focal_terms = ['Digitalisierung','Zusammenhalt','Demokratie']\n",
    "#focal_terms = ['Digitalisierung']\n",
    "#focal_terms = ['Plattform','Demokratie']\n",
    "#focal_terms = ['extrem','Plattform']\n",
    "#focal_terms = ['plattform','demokratie']\n",
    "#focal_terms = ['Plattform','Meinung']\n",
    "#focal_terms = ['Netzwerk','Meinung']\n",
    "focal_terms = ['Ukraine']\n",
    "subset = filter_for('text', focal_terms, speeches)\n",
    "len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:08<00:00, 11.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "#focal_terms_sen = ['Netzwerk','sozial']\n",
    "focal_terms_sen = ['Russland']\n",
    "window = 10\n",
    "for rede in tqdm.tqdm(subset):\n",
    "    doc = nlp(rede[\"text\"])\n",
    "    #print(rede['name'])\n",
    "    for sent in doc.sents:\n",
    "        #print(sent.text)\n",
    "        if all(ft.lower() in sent.text.lower() for ft in focal_terms_sen):\n",
    "        #if focal_terms[0].lower() in sent.text.lower() and focal_terms[1].lower() in sent.text.lower():\n",
    "        #for focus in focal_terms:    \n",
    "            #if focus in sent.text:\n",
    "            sentences.append(sent)\n",
    "        \n",
    "        \n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Zum einen – und das ist die Mehrheitsmeinung im deutschen Volke – geht es um die Lesbarkeit von Drucksachen durch Verzicht auf die sogenannte Gendersprache.,\n",
       " Also, Sie können was für unser Volk, für die Mehrheit des Volkes, tun.]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6378"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevantPOS = ['NOUN','ADJ','PROPN']\n",
    "sentencesNN = []\n",
    "words = []\n",
    "for sen in sentences:\n",
    "    lem = []\n",
    "    for token in sen:\n",
    "        if token.pos_ in relevantPOS:\n",
    "            lem.append(token.lemma_)\n",
    "    sentencesNN.append(lem)\n",
    "    words.extend(lem)\n",
    "#sentencesNN\n",
    "len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Krieg',\n",
       " 'Europa',\n",
       " 'Land',\n",
       " 'Angriffskrieg',\n",
       " 'Deutschland',\n",
       " 'Putin',\n",
       " 'Sanktion',\n",
       " 'Mensch',\n",
       " 'ander',\n",
       " 'Jahr',\n",
       " 'Prozent',\n",
       " 'groß',\n",
       " 'russisch',\n",
       " 'militärisch',\n",
       " 'NATO',\n",
       " 'Staat',\n",
       " 'Tag',\n",
       " 'letzt',\n",
       " 'deutsch',\n",
       " 'Sicherheit',\n",
       " 'europäisch',\n",
       " 'China',\n",
       " 'Abhängigkeit',\n",
       " 'Putins',\n",
       " 'klaren',\n",
       " 'wichtig',\n",
       " 'Welt',\n",
       " 'unabhängig',\n",
       " 'Seite',\n",
       " 'USA',\n",
       " 'Weg',\n",
       " 'gemeinsam',\n",
       " 'Angriff',\n",
       " 'wirtschaftlich',\n",
       " 'Teil',\n",
       " 'Gas',\n",
       " 'Grenze',\n",
       " 'europäische',\n",
       " 'Regierung',\n",
       " 'Situation',\n",
       " 'Aggression',\n",
       " 'abhängig',\n",
       " 'massiv',\n",
       " 'gut',\n",
       " 'Westen',\n",
       " 'Druck',\n",
       " 'Präsident',\n",
       " 'Beispiel',\n",
       " 'völkerrechtswidrigen',\n",
       " 'weit',\n",
       " 'aktuell',\n",
       " 'fossil',\n",
       " 'Energie',\n",
       " 'Konflikt',\n",
       " 'Demokratie',\n",
       " 'Friede',\n",
       " 'Frage',\n",
       " 'Bundesregierung',\n",
       " 'Blick',\n",
       " 'Friedensordnung',\n",
       " 'russische',\n",
       " 'Konsequenz',\n",
       " 'Ende',\n",
       " 'Öl',\n",
       " 'Überfall',\n",
       " 'Krim',\n",
       " 'Union',\n",
       " 'deutlich',\n",
       " 'Herausforderung',\n",
       " 'Zeit',\n",
       " 'Woche',\n",
       " 'völkerrechtswidrige',\n",
       " 'Folge',\n",
       " 'stark',\n",
       " 'Interesse',\n",
       " 'Volk',\n",
       " 'Bundeskanzler',\n",
       " 'Bundestag',\n",
       " 'Belarus',\n",
       " 'Zukunft',\n",
       " 'Bedrohung',\n",
       " 'deutschen',\n",
       " 'Souveränität',\n",
       " 'politisch',\n",
       " 'Sorge',\n",
       " 'Partner',\n",
       " 'Debatte',\n",
       " 'Haus',\n",
       " 'Ding',\n",
       " 'Ziel',\n",
       " 'eigen',\n",
       " 'Bevölkerung',\n",
       " 'EU',\n",
       " 'Welle',\n",
       " 'Maßnahme',\n",
       " 'Mittel',\n",
       " 'richtig',\n",
       " 'Ordnung',\n",
       " 'Weißrussland',\n",
       " 'Europäische',\n",
       " 'Gespräch',\n",
       " 'ukrainisch',\n",
       " 'Thema',\n",
       " 'neu',\n",
       " 'hart',\n",
       " 'Deutsche',\n",
       " 'Wirtschaft',\n",
       " 'Angst',\n",
       " 'Bezug',\n",
       " 'Krise',\n",
       " 'möglich',\n",
       " 'Straße',\n",
       " 'Integrität',\n",
       " 'Völkerrecht',\n",
       " 'Beziehung',\n",
       " 'Richtung',\n",
       " 'Politik',\n",
       " 'Soldat',\n",
       " 'Rolle',\n",
       " 'Verhandlung',\n",
       " 'Hand',\n",
       " 'Unternehmen',\n",
       " 'Stelle',\n",
       " 'Partei',\n",
       " 'Entwicklung',\n",
       " 'Medium',\n",
       " 'Merz',\n",
       " 'Verbrechen',\n",
       " 'Bereich',\n",
       " 'ganz',\n",
       " 'Gefahr',\n",
       " 'Antrag',\n",
       " 'genau',\n",
       " 'Beitrag',\n",
       " 'Wladimir',\n",
       " 'weltweit',\n",
       " 'Truppe',\n",
       " 'wirklich',\n",
       " 'Weise',\n",
       " 'Reaktion',\n",
       " 'früh',\n",
       " 'Kritik',\n",
       " 'Recht',\n",
       " 'direkt',\n",
       " 'finanziell',\n",
       " 'Atommacht',\n",
       " 'Wort',\n",
       " 'AfD',\n",
       " 'Freiheit',\n",
       " 'Freund',\n",
       " 'Auge',\n",
       " 'humanitär',\n",
       " 'Europarat',\n",
       " 'Entscheidung',\n",
       " 'mutig',\n",
       " 'international',\n",
       " 'Moment',\n",
       " 'brutal',\n",
       " 'Getreide',\n",
       " 'Angriffskrieges',\n",
       " 'schnellen',\n",
       " 'Februar',\n",
       " 'Markt',\n",
       " 'Moldau',\n",
       " 'Hintergrund',\n",
       " 'Unterstützung',\n",
       " 'Verantwortung',\n",
       " 'Realität',\n",
       " 'Georgien',\n",
       " 'westlich',\n",
       " 'Stunde',\n",
       " 'Schluss',\n",
       " 'Sicht',\n",
       " 'Verhältnis',\n",
       " 'steigend',\n",
       " 'Nachbar',\n",
       " 'Bürgerin',\n",
       " 'Bürger',\n",
       " 'Grundlage',\n",
       " 'verschieden',\n",
       " 'lang',\n",
       " 'Umgang',\n",
       " 'Projekt',\n",
       " 'Respekt',\n",
       " 'erheblich',\n",
       " 'Waffe',\n",
       " 'Gysi',\n",
       " 'offen',\n",
       " 'Hilfe',\n",
       " 'Grund',\n",
       " 'Linke',\n",
       " 'Diskussion',\n",
       " 'dramatisch',\n",
       " 'friedlich',\n",
       " 'Zweite',\n",
       " 'Million',\n",
       " 'Menschenrechte',\n",
       " 'Auseinandersetzung',\n",
       " 'Journalistin',\n",
       " 'Kreml']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zähler = collections.Counter(words).most_common()\n",
    "#print(zähler)\n",
    "\n",
    "words_clean = []\n",
    "#print(focal_terms_sen)\n",
    "for word in words:\n",
    "    if focal_terms_sen[0] in word or focal_terms[0] in word or 'Herr' in word or 'Dame' in word or 'Kollege' in word or 'Kollegin' in word or \"/\" in word:\n",
    "        pass\n",
    "    else:\n",
    "        words_clean.append(word)\n",
    "    \n",
    "#print(len(words_clean))\n",
    "zähler = collections.Counter(words_clean).most_common()\n",
    "#print(zähler)\n",
    "\n",
    "num_words = 200\n",
    "count = 0\n",
    "new_words = []\n",
    "for word in zähler:\n",
    "    #print(word[0])\n",
    "    if count < num_words:\n",
    "        new_words.append(word[0])\n",
    "    count = count + 1    \n",
    "        \n",
    "new_words        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3792 3792\n"
     ]
    }
   ],
   "source": [
    "nodes=[]\n",
    "curid=1\n",
    "for word in set(new_words):\n",
    "    node = {\n",
    "    'id' :  curid,\n",
    "    'name' : word\n",
    "    }\n",
    "    nodes.append(node)\n",
    "    curid=curid+1\n",
    "    \n",
    "graph = {\n",
    "    'directed': False,\n",
    "    'graph': 'word_graph',\n",
    "    'links': [],\n",
    "    'nodes': nodes\n",
    "}\n",
    "\n",
    "links = []\n",
    "linkedwords =[]\n",
    "linkedids =[]\n",
    "lx = 0;\n",
    "for wx1,w1 in enumerate(nodes):\n",
    "    #print(wx1)\n",
    "    for wx2,w2 in enumerate(nodes):\n",
    "        if(w2['id'] > w1['id']):\n",
    "            for sen in sentencesNN:\n",
    "                if w1['name'] in sen and w2['name'] in sen:\n",
    "                    weight = len([ele for ele in linkedwords if ele == (' '.join([w1['name'],w2['name']]))])\n",
    "                    #    links[]\n",
    "                    #else:\n",
    "                    #print(weight)\n",
    "                    linkedwords.append(' '.join([w1['name'],w2['name']]))\n",
    "                    #linkedids[ w1['id'] ] , w2['id'] )\n",
    "                    link_dict = {\n",
    "                    'source':w1['id'],\n",
    "                    'target':w2['id'],\n",
    "                    'sourceWD':w1['name'],\n",
    "                    'targetWD':w2['name'],\n",
    "                    'weight': weight+1      \n",
    "                    }\n",
    "                    #print(link_dict)\n",
    "                    links.append(link_dict)\n",
    "                    graph['links'].append(link_dict)\n",
    "               \n",
    "                    #for link in links:\n",
    "\n",
    "#linkedwords\n",
    "zähler = collections.Counter(linkedwords).most_common()\n",
    "print(len(linkedwords),len(links))\n",
    "#graph['links']=links\n",
    "#print(zähler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3792 200\n"
     ]
    }
   ],
   "source": [
    "print(len(graph['links']),\n",
    "len(graph['nodes']))\n",
    "#for link in graph['links']:\n",
    "#    if link['weight']>1:\n",
    "        #print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 203656.42it/s]\n",
      "100%|██████████| 3792/3792 [00:00<00:00, 408255.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes done\n",
      "links done\n",
      "save done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "graphforgephi = nx.Graph()\n",
    "for node in tqdm.tqdm(graph['nodes']):\n",
    "    graphforgephi.add_node(node['id'],name = node['name']);\n",
    "print('nodes done')\n",
    "for link in tqdm.tqdm(graph['links']):\n",
    "    #weight = all((' '.join([w1['name'],w2['name']]) in linkedwords)\n",
    "    #print(weight)         \n",
    "    graphforgephi.add_edge(link['source'],link['target'],weight=link['weight'])\n",
    "print('links done')   \n",
    "nx.write_gexf(graphforgephi, \"graphforgephi.gexf\")\n",
    "print('save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netzwerk mit übereinstimmenden Tagesordnungspunkten als Gewichte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import collections\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/speeches_preprocessed.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "    \n",
    "alleReden = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reden = alleReden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtern auf Meta-Informationen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_reden(reden):\n",
    "    \n",
    "    redeinfo_list = []\n",
    "    \n",
    "    for rede in reden:\n",
    "\n",
    "        input_dict = {\n",
    "        'date'  : rede[\"date\"],\n",
    "        'discussion_title' : rede[\"discussion_title\"],\n",
    "        'name'  : rede[\"name\"],\n",
    "        'party' : rede[\"party\"],\n",
    "        }\n",
    "        redeinfo_list.append(input_dict)\n",
    "        \n",
    "    return redeinfo_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redeinfo_list = filter_reden(reden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste aller Parlamentarier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liste_aller_parlamentarier(reden):\n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    for rede in reden:\n",
    "        if rede['name'] not in names:\n",
    "            names.append(rede['name'])\n",
    "    \n",
    "    return names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = liste_aller_parlamentarier(redeinfo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrukturierung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten werden in eine Liste von Dictionaries übertragen. Jeder Parlamentarier erhält ein Dictionary in dieser Liste, wobei jedes Dictionary eine Liste mit den TOPs, in denen der jeweilige Parlamentarier gesprochen hat, erhält.\n",
    "Zusätzlich enthält jedes Dictionary eine ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liste_von_parla_mit_dict(reden, names):\n",
    "    \n",
    "    parlamentarier = []\n",
    "\n",
    "    for count,name in tqdm(enumerate(names)):\n",
    "        hilf = {\n",
    "            'id':count+1,\n",
    "            'name': name,\n",
    "            'text_lem': []\n",
    "        }\n",
    "        tops = []\n",
    "        text = []\n",
    "        for rede in reden:\n",
    "            if rede['name'] == name:\n",
    "                text = text + rede['text_lem']\n",
    "                hilf.update({'party': rede['party']})\n",
    "                \n",
    "                if rede['discussion_title'] not in tops:\n",
    "                    tops.append(rede['discussion_title'])\n",
    "                    #print(rede['discussion_title'])\n",
    "                    \n",
    "        hilf.update({'tops': tops,'text_lem':text})\n",
    "        parlamentarier.append(hilf)\n",
    "    \n",
    "    return parlamentarier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parlamentarier = liste_von_parla_mit_dict(reden, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parlamentarier[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [ \" \".join(parla['text_lem']) for parla in parlamentarier ]\n",
    "vectorizer = CountVectorizer(max_df=0.8, min_df=(2/781))\n",
    "f_word = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, name in tqdm(enumerate(parlamentarier)):\n",
    "    \n",
    "    vec_numbers = np.array(f_word.getrow(count).toarray()[0])\n",
    "    msw = list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(np.argmax(vec_numbers))]\n",
    "    name.update({'msw':msw})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen der Kanten des coTOP-Graphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cotop_graph_erstellen(parlamentarier, min_weight):\n",
    "\n",
    "    graph = {\n",
    "        'directed': False,\n",
    "        'graph': 'coTOP_graph',\n",
    "        'links': [],\n",
    "        'nodes': parlamentarier,\n",
    "    }\n",
    "\n",
    "    for ix,nodeI in enumerate(graph['nodes']):\n",
    "        for jx,nodeJ in enumerate(graph['nodes']):\n",
    "            if nodeI['id'] < nodeJ['id']:\n",
    "                source = nodeI['id']\n",
    "                target = nodeJ['id']\n",
    "                topsI = set(nodeI['tops'])\n",
    "                topsJ = set(nodeJ['tops'])\n",
    "                weight = len(topsI.intersection(topsJ))  # length of intersection as weight\n",
    "                if weight >= min_weight:\n",
    "                    link_dict = {\n",
    "                        'source':source,\n",
    "                        'target':target,\n",
    "                        'weight':weight       \n",
    "                    }\n",
    "                    graph['links'].append(link_dict)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = cotop_graph_erstellen(parlamentarier, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Auswerten der Anzahl der Kanten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = len(graph['nodes'])\n",
    "ne = len(graph['links'])\n",
    "print( f\"This graph has {nn} nodes and {ne} links.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "weights=[]\n",
    "for link in graph['links']:\n",
    "    weights.append(link['weight'])\n",
    "#print(sum(weights))\n",
    "\n",
    "plt.hist(weights, bins=25)\n",
    "plt.title(\"Distribution of Weights\")\n",
    "plt.xlabel(\"Wert\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw the HTML/JS Graph\n",
    "\n",
    "In der Tat: 50000 Kanten ist viel. Vielleicht auch zu viel für Gephi. Wir werden sehen. Aber darüber hinaus habe ich irgendwie nicht erwartet, dass diese Graphen so dicht (viele Kanten) sind. \n",
    "\n",
    "(Nun wissen wir, dass es teilweise sehr viele Redner per TOP gibt, siehe unten.)\n",
    "\n",
    "#### Dauert sehr lange. Skip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cotop_graph(graph):\n",
    "    \n",
    "    json = {'data': graph,\n",
    "            'nodecoloring': 'party',\n",
    "            'nodelabel': 'name',\n",
    "            \"darkmode\": False,\n",
    "            \"edgevisibility\": False,\n",
    "            \"particles\": False\n",
    "            }\n",
    "    print(\"previsualizer\")\n",
    "    result = requests.post('https://penelope.vub.be/network-components/visualiser', json=json)\n",
    "    print(\"presave\")\n",
    "    with open(f\"./redenetTOPS.html\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(result.json()['graph'])\n",
    "    print(\"savedone\")\n",
    "\n",
    "visualize_cotop_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Gephi-readable File\n",
    "\n",
    "Also versuchen wir Gephi. Wir brauchen die networkx package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_penelope_to_networkx(graph):\n",
    "    graph_nx = nx.Graph()\n",
    "    \n",
    "    for node in graph['nodes']:\n",
    "        graph_nx.add_node(node['id'], name=node['name'], party=node['party'], msw=node['msw'])\n",
    "\n",
    "    print('nodes done')\n",
    "    \n",
    "    for link in graph['links']:   \n",
    "        graph_nx.add_edge(link['source'],link['target'],weight = link['weight'])\n",
    "    print('links done')   \n",
    "    \n",
    "    return graph_nx\n",
    "\n",
    "def save_coTOP(graph_nx, dateiname):\n",
    "    nx.write_gexf(graph_nx, dateiname)\n",
    "    print('save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nx = conv_penelope_to_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_coTOP(graph_nx, \"graph_coTOP_nx.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate semantic similarity networks of all speeches\n",
    "\n",
    "This is a pipeline to create the semantic similarity network of all speeches.\n",
    "\n",
    "\n",
    "#### 1. Import the basic stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/speeches_preprocessed.json', 'r') as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reden = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step of data cleaning can be skipped!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean party labels\n",
    "for rede in reden:\n",
    "    rede['party']=rede['party'].replace(u'\\xa0', u' ')\n",
    "    if rede['party']=='Bündnis 90/Die Grünen':\n",
    "        rede['party']='BÜNDNIS 90/DIE GRÜNEN'\n",
    "    if rede['party']=='Fraktionslos':\n",
    "        rede['party']='fraktionslos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Data selection\n",
    "\n",
    "Now select, if desired, a subset of speeches by party, parlamentarians, date, etc. Note that it does not work for the 'text'-field, but 'text_lem' should work.\n",
    "\n",
    "To be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2017-10-24',\n",
       " 'discussion_title': 'Tagesordnungspunkt 1 2017-10-24',\n",
       " 'id': 'ID19100100',\n",
       " 'name': 'Alterspräsident Dr. Hermann Otto Solms',\n",
       " 'party': 'FDP',\n",
       " 'period': '19',\n",
       " 'text': 'Guten Morgen, liebe Kolleginnen und Kollegen! Nehmen Sie bitte Platz. Meine sehr verehrten Damen und Herren! Liebe Kolleginnen und Kollegen! Ich begrüße Sie zur konstituierenden Sitzung des 19. Deutschen Bundestages. Es entspricht der ständigen Übung, zu Beginn der konstituierenden Sitzung nach den Regelungen der bisherigen Geschäftsordnung des Deutschen Bundestages zu verfahren. § 1 Absatz 2 der Geschäftsordnung des Deutschen Bundestages sieht vor, dass das am längsten dem Bundestag angehörende Mitglied, das hierzu bereit ist, den Vorsitz übernimmt, bis der Deutsche Bundestag einen Präsidenten gewählt hat. Die Fraktion der AfD widerspricht diesem Verfahren und hat auf Drucksache 19/2 beantragt, einen Versammlungsleiter zu wählen, der die konstituierende Sitzung eröffnen soll. Über diesen Antrag lasse ich sofort abstimmen. Wer dem Antrag der Fraktion der AfD zustimmt, den bitte ich um sein Handzeichen. – Gegenstimmen? – Enthaltungen? – Der Antrag ist damit mit den Stimmen aller Fraktionen bei Zustimmung der AfD-Fraktion abgelehnt. Wir verfahren nunmehr entsprechend § 1 Absatz 2 der bisherigen Geschäftsordnung. Herr Dr. Wolfgang Schäuble ist das Mitglied, das dem Deutschen Bundestag am längsten angehört. Er hat jedoch auf das Amt des Alterspräsidenten verzichtet. Damit rückt das am zweitlängsten dem Bundestag angehörende Mitglied nach. Ich war von 1980 bis 2013, also 33 Jahre, Mitglied des Deutschen Bundestages. Ist jemand unter Ihnen, der dem Bundestag länger angehört? – Das scheint offenkundig nicht der Fall zu sein. Dann trifft es also tatsächlich zu, dass die Rolle des Alterspräsidenten auf mich zukommt. Es ist mir eine Ehre und Freude zugleich, den Vorsitz bis zur Amtsübernahme durch den neugewählten Präsidenten des Deutschen Bundestages zu übernehmen. ',\n",
       " 'text_lem': ['Guten',\n",
       "  'Morgen',\n",
       "  ',',\n",
       "  'lieb',\n",
       "  'Kollegin',\n",
       "  'und',\n",
       "  'Kollege',\n",
       "  '!',\n",
       "  'Nehmen',\n",
       "  'ich',\n",
       "  'bitte',\n",
       "  'Platz',\n",
       "  '.',\n",
       "  'Meine',\n",
       "  'sehr',\n",
       "  'verehren',\n",
       "  'Dame',\n",
       "  'und',\n",
       "  'Herr',\n",
       "  '!',\n",
       "  'lieben',\n",
       "  'Kollegin',\n",
       "  'und',\n",
       "  'Kollege',\n",
       "  '!',\n",
       "  'Ich',\n",
       "  'begrüßen',\n",
       "  'ich',\n",
       "  'zur',\n",
       "  'konstituierend',\n",
       "  'Sitzung',\n",
       "  'der',\n",
       "  '19.',\n",
       "  'Deutsche',\n",
       "  'Bundestag',\n",
       "  '.',\n",
       "  'ich',\n",
       "  'entsprechen',\n",
       "  'der',\n",
       "  'ständig',\n",
       "  'Übung',\n",
       "  ',',\n",
       "  'zu',\n",
       "  'Beginn',\n",
       "  'der',\n",
       "  'konstituierend',\n",
       "  'Sitzung',\n",
       "  'nach',\n",
       "  'der',\n",
       "  'Regelung',\n",
       "  'der',\n",
       "  'bisherig',\n",
       "  'Geschäftsordnung',\n",
       "  'der',\n",
       "  'Deutsche',\n",
       "  'Bundestag',\n",
       "  'zu',\n",
       "  'verfahren',\n",
       "  '.',\n",
       "  '§',\n",
       "  '1',\n",
       "  'Absatz',\n",
       "  '2',\n",
       "  'der',\n",
       "  'Geschäftsordnung',\n",
       "  'der',\n",
       "  'Deutsche',\n",
       "  'Bundestag',\n",
       "  'sehen',\n",
       "  'vor',\n",
       "  ',',\n",
       "  'dass',\n",
       "  'der',\n",
       "  'am',\n",
       "  'lang',\n",
       "  'der',\n",
       "  'Bundestag',\n",
       "  'angehörend',\n",
       "  'Mitglied',\n",
       "  ',',\n",
       "  'der',\n",
       "  'hierzu',\n",
       "  'bereiten',\n",
       "  'sein',\n",
       "  ',',\n",
       "  'der',\n",
       "  'Vorsitz',\n",
       "  'übernehmen',\n",
       "  ',',\n",
       "  'bis',\n",
       "  'der',\n",
       "  'deutschen',\n",
       "  'Bundestag',\n",
       "  'ein',\n",
       "  'Präsident',\n",
       "  'wählen',\n",
       "  'haben',\n",
       "  '.',\n",
       "  'der',\n",
       "  'Fraktion',\n",
       "  'der',\n",
       "  'AfD',\n",
       "  'widersprechen',\n",
       "  'dies',\n",
       "  'Verfahren',\n",
       "  'und',\n",
       "  'haben',\n",
       "  'auf',\n",
       "  'Drucksache',\n",
       "  '19',\n",
       "  '/',\n",
       "  '2',\n",
       "  'beantragen',\n",
       "  ',',\n",
       "  'ein',\n",
       "  'Versammlungsleiter',\n",
       "  'zu',\n",
       "  'wählen',\n",
       "  ',',\n",
       "  'der',\n",
       "  'der',\n",
       "  'konstituierend',\n",
       "  'Sitzung',\n",
       "  'eröffnen',\n",
       "  'soll',\n",
       "  '.',\n",
       "  'Über',\n",
       "  'dies',\n",
       "  'Antrag',\n",
       "  'lassen',\n",
       "  'ich',\n",
       "  'sofort',\n",
       "  'abstimmen',\n",
       "  '.',\n",
       "  'Wer',\n",
       "  'der',\n",
       "  'Antrag',\n",
       "  'der',\n",
       "  'Fraktion',\n",
       "  'der',\n",
       "  'AfD',\n",
       "  'zustimmen',\n",
       "  ',',\n",
       "  'der',\n",
       "  'bitte',\n",
       "  'ich',\n",
       "  'um',\n",
       "  'mein',\n",
       "  'Handzeichen',\n",
       "  '.',\n",
       "  '–',\n",
       "  'Gegenstimmen',\n",
       "  '?',\n",
       "  '–',\n",
       "  'Enthaltung',\n",
       "  '?',\n",
       "  '–',\n",
       "  'der',\n",
       "  'Antrag',\n",
       "  'sein',\n",
       "  'damit',\n",
       "  'mit',\n",
       "  'der',\n",
       "  'Stimme',\n",
       "  'all',\n",
       "  'Fraktion',\n",
       "  'bei',\n",
       "  'Zustimmung',\n",
       "  'der',\n",
       "  'AfD-Fraktion',\n",
       "  'ablehnen',\n",
       "  '.',\n",
       "  'ich',\n",
       "  'verfahren',\n",
       "  'nunmehr',\n",
       "  'entsprechen',\n",
       "  '§',\n",
       "  '1',\n",
       "  'Absatz',\n",
       "  '2',\n",
       "  'der',\n",
       "  'bisherig',\n",
       "  'Geschäftsordnung',\n",
       "  '.',\n",
       "  'Herr',\n",
       "  'Dr.',\n",
       "  'Wolfgang',\n",
       "  'Schäuble',\n",
       "  'sein',\n",
       "  'der',\n",
       "  'Mitglied',\n",
       "  ',',\n",
       "  'der',\n",
       "  'der',\n",
       "  'Deutsche',\n",
       "  'Bundestag',\n",
       "  'am',\n",
       "  'lang',\n",
       "  'anhören',\n",
       "  '.',\n",
       "  'ich',\n",
       "  'haben',\n",
       "  'jedoch',\n",
       "  'auf',\n",
       "  'der',\n",
       "  'Amt',\n",
       "  'der',\n",
       "  'Alterspräsidenten',\n",
       "  'verzichten',\n",
       "  '.',\n",
       "  'damit',\n",
       "  'rücken',\n",
       "  'der',\n",
       "  'am',\n",
       "  'zweitlängsten',\n",
       "  'der',\n",
       "  'Bundestag',\n",
       "  'angehörend',\n",
       "  'Mitglied',\n",
       "  'nach',\n",
       "  '.',\n",
       "  'Ich',\n",
       "  'sein',\n",
       "  'von',\n",
       "  '1980',\n",
       "  'bis',\n",
       "  '2013',\n",
       "  ',',\n",
       "  'also',\n",
       "  '33',\n",
       "  'Jahr',\n",
       "  ',',\n",
       "  'Mitglied',\n",
       "  'der',\n",
       "  'Deutsche',\n",
       "  'Bundestag',\n",
       "  '.',\n",
       "  'sein',\n",
       "  'jemand',\n",
       "  'unter',\n",
       "  'ich',\n",
       "  ',',\n",
       "  'der',\n",
       "  'der',\n",
       "  'Bundestag',\n",
       "  'lang',\n",
       "  'anhören',\n",
       "  '?',\n",
       "  '–',\n",
       "  'der',\n",
       "  'scheinen',\n",
       "  'offenkundig',\n",
       "  'nicht',\n",
       "  'der',\n",
       "  'Fall',\n",
       "  'zu',\n",
       "  'mein',\n",
       "  '.',\n",
       "  'Dann',\n",
       "  'treffen',\n",
       "  'ich',\n",
       "  'also',\n",
       "  'tatsächlich',\n",
       "  'zu',\n",
       "  ',',\n",
       "  'dass',\n",
       "  'der',\n",
       "  'Rolle',\n",
       "  'der',\n",
       "  'Alterspräsidenten',\n",
       "  'auf',\n",
       "  'sich',\n",
       "  'zukommen',\n",
       "  '.',\n",
       "  'ich',\n",
       "  'sein',\n",
       "  'sich',\n",
       "  'einen',\n",
       "  'Ehre',\n",
       "  'und',\n",
       "  'Freude',\n",
       "  'zugleich',\n",
       "  ',',\n",
       "  'der',\n",
       "  'Vorsitz',\n",
       "  'bis',\n",
       "  'zur',\n",
       "  'Amtsübernahme',\n",
       "  'durch',\n",
       "  'der',\n",
       "  'neugewählten',\n",
       "  'Präsident',\n",
       "  'der',\n",
       "  'Deutsche',\n",
       "  'Bundestag',\n",
       "  'zu',\n",
       "  'übernehmen',\n",
       "  '.'],\n",
       " 'text_pos': ['ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'CCONJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'ADV',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'CCONJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'CCONJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  'ADP',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'ADP',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PART',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'X',\n",
       "  'NUM',\n",
       "  'NOUN',\n",
       "  'NUM',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'PUNCT',\n",
       "  'SCONJ',\n",
       "  'PRON',\n",
       "  'PART',\n",
       "  'ADJ',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'ADV',\n",
       "  'ADJ',\n",
       "  'AUX',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'SCONJ',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'AUX',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'PROPN',\n",
       "  'VERB',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'CCONJ',\n",
       "  'AUX',\n",
       "  'ADP',\n",
       "  'NOUN',\n",
       "  'NUM',\n",
       "  'PUNCT',\n",
       "  'NUM',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'PART',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  'ADV',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'PROPN',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'ADV',\n",
       "  'PRON',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'AUX',\n",
       "  'ADV',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'ADV',\n",
       "  'ADP',\n",
       "  'NOUN',\n",
       "  'NUM',\n",
       "  'NOUN',\n",
       "  'NUM',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'NOUN',\n",
       "  'NOUN',\n",
       "  'PROPN',\n",
       "  'PROPN',\n",
       "  'AUX',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PART',\n",
       "  'ADJ',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'AUX',\n",
       "  'ADV',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'ADV',\n",
       "  'VERB',\n",
       "  'DET',\n",
       "  'PART',\n",
       "  'ADJ',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'AUX',\n",
       "  'ADP',\n",
       "  'NUM',\n",
       "  'ADP',\n",
       "  'NUM',\n",
       "  'PUNCT',\n",
       "  'ADV',\n",
       "  'NUM',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'AUX',\n",
       "  'PRON',\n",
       "  'ADP',\n",
       "  'PRON',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADJ',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'ADJ',\n",
       "  'PART',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'PART',\n",
       "  'AUX',\n",
       "  'PUNCT',\n",
       "  'ADV',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  'ADV',\n",
       "  'ADJ',\n",
       "  'ADP',\n",
       "  'PUNCT',\n",
       "  'SCONJ',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'PUNCT',\n",
       "  'PRON',\n",
       "  'AUX',\n",
       "  'PRON',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'CCONJ',\n",
       "  'NOUN',\n",
       "  'ADV',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'ADP',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PART',\n",
       "  'VERB',\n",
       "  'PUNCT']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set(reden[0]['name'])\n",
    "reden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_for(what, search_terms, speeches):\n",
    "    filtered_speeches = []\n",
    "    for speech in speeches:\n",
    "        if ( speech[what] in set(search_terms) ):\n",
    "            filtered_speeches.append(speech)\n",
    "    filtered_speeches.sort(key = lambda x:x['date']) \n",
    "    return filtered_speeches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "members = ['Hansjörg Durz','Birke Bull-Bischoff','Stefan Kaufmann','Ernst Dieter Rossmann','Götz Frömming','Katja Suding','Kai Gehring','Tankred Schipanski','Saskia Esken','Oliver Kaczmarek','Nicola Beer','Anke Domscheit-Berg','Tabea Rößner','Manuel Höferlin','Sven Lehmann','Karamba Diaby','Susann Rüthrich','Katarina Barley','Sylvia Pantel','Johannes Huber','Katrin Werner','Grigorios Aggelidis','Katja Dörner','Martin Reichardt','Nadine Schön','Nicole Höchst','Stefan Schwartze','Norbert Müller','Uwe Schulz','Maik Beermann','Josephine Ortleb','Cornelia Möhring','Ulle Schauws','Silke Launert','Wiebke Esdar','Gülistan Yüksel','Matthias Seestern-Pauly','Marcus Weinberg','Martin Patzelt','Dagmar Schmidt','Anna Christmann','Uwe Kamann','Silvia Breher','Nicole Bauer','Leni Breymaier','Katrin Helling-Plahr','Annalena Baerbock','Petra Sitte','Mariana Iris Harder-Kühnel','Katja Mast','Roman Müller-Böhm','Doris Achelwilm','Yvonne Magwas','Sönke Rix','Ronja Kemmer','Margit Stumpp','Manja Schüle','Jens Brandenburg','Nicole Gohlke','Katrin Staffler','Beate Walter-Rosenheimer','Bettina Margarethe Wiesmann','Ulrike Bahr','Franziska Giffey','Anja Karliczek','Michaela Noll','Yasmin Fahimi','Melanie Bernstein','Stephan Albani','Marja-Liisa Völlers','Thomas Sattelberger','Dietlind Tiemann','René Röspel','Albert Rupprecht','Michael Espendiller','Joana Cotar','Mario Brandenburg','Volker Münz','Astrid Mannes','Ekin Deligöz','Stefan Sauer','Svenja Stadler','Swen Schulz','Kerstin Radomski','Johannes Steiniger','Caren Marks','Andreas Steier','Dieter Janecek','Sybille Benning','Thomas Rachel','Dorothee Bär','Frank Pasemann','Lars Klingbeil','Ingrid Pahlmann','Markus Paschke','Elvan Korkmaz-Emre','Charlotte Schneidewind-Hartnagel']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reden_selection = filter_for('name', members, reden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reden_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4efa0a84626e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreden_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reden_selection' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "reden = reden_selection\n",
    "len(reden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(reden[5102]['text_lem']))\n",
    "print(reden[5102]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build corpus and count word frequencies per party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24666/24666 [00:02<00:00, 8914.12it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "allwords = []\n",
    "\n",
    "minlength = -20;\n",
    "\n",
    "# prepare for per party counts\n",
    "allwordsperparty = {\n",
    "    'SPD':[],\n",
    "    'FDP':[],\n",
    "    'CDU/CSU':[],\n",
    "    'DIE LINKE':[],\n",
    "    'BÜNDNIS 90/DIE GRÜNEN':[],\n",
    "    'AfD':[],\n",
    "    'fraktionslos':[],\n",
    "    'Bremen':[]   \n",
    "}\n",
    "        \n",
    "#consider = ['PROPN']\n",
    "#consider = ['ADJ']\n",
    "consider = ['NOUN']\n",
    "for rede in tqdm.tqdm(reden):\n",
    "    if(len(rede['text_lem']) > minlength):\n",
    "    #rel_lemmata = [ ele for ex,ele in enumerate(rede['text_lem']) if (rede['text_pos'][ex] in consider and len(ele) > 7 and len(ele) < 16)]\n",
    "        rel_lemmata = [ ele for ex,ele in enumerate(rede['text_lem']) if rede['text_pos'][ex] in consider ]\n",
    "        allwords.extend(rel_lemmata)\n",
    "        allwordsperparty[rede['party']].extend(rel_lemmata)\n",
    "        corpus.append( \" \".join(rel_lemmata ))\n",
    "   \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Semantic Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer_selection = CountVectorizer(vocabulary = features02, decode_error='ignore' , lowercase=False, ngram_range=(1, 1))\n",
    "vectorizer = CountVectorizer(decode_error='ignore' , lowercase=False , max_df=0.8, min_df=2, ngram_range=(1, 1))\n",
    "mm = vectorizer.fit_transform(corpus)\n",
    "features = vectorizer.get_feature_names()\n",
    "print(f'We now consider {len(features)} different words.')\n",
    "print(mm.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that via TFIDF this is way faster!\n",
    "SemSimMat = cosine_similarity(mm)\n",
    "print(SemSimMat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24666, 60262)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(lowercase=False,max_df=0.8, min_df=2/len(corpus))\n",
    "mm_tfidf  = vectorizer_tfidf.fit_transform(corpus)\n",
    "features = vectorizer_tfidf.get_feature_names()\n",
    "mm_tfidf.get_shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24666, 24666)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SemSimMat_tfidf = mm_tfidf * mm_tfidf.T\n",
    "SemSimMat_tfidf.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reden[0] \n",
    "print(SemSimMat_tfidf[10,2003])\n",
    "print(SemSimMat[10,2003])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes = []\n",
    "for rx,rede in enumerate(reden):\n",
    "    node = {\n",
    "        'id' :  rede['id'],\n",
    "        'name' : rede['name'],\n",
    "        'date' : rede['date'],\n",
    "        'discussion_title' : rede['discussion_title'],\n",
    "        'party' : rede['party'],\n",
    "        'length' : len(rede['text_lem']),\n",
    "        #'text' : rede['text']\n",
    "    }\n",
    "    \n",
    "    nodes.append(node)\n",
    "    \n",
    "\n",
    "graph = {\n",
    "    'directed': False,\n",
    "    'graph': 'word_graph',\n",
    "    'links': [],\n",
    "    'nodes': nodes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0]\n",
    "#SemSimMat_tfidf.mean()\n",
    "SimMat = SemSimMat_tfidf.todense()\n",
    "vectorizer = vectorizer_tfidf\n",
    "mm = mm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24666it [08:57, 45.92it/s]\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "\n",
    "min_weight = 0.2222\n",
    "for ix,nodeI in tqdm.tqdm(enumerate(graph['nodes'])):\n",
    "    for jx,nodeJ in enumerate(graph['nodes']):\n",
    "        if nodeI['id'] < nodeJ['id']:          \n",
    "            source = nodeI['id']\n",
    "            target = nodeJ['id']\n",
    "            weight = SimMat[ix,jx]\n",
    "            if weight > min_weight:\n",
    "                #links.append([source,target,weight])\n",
    "                link_dict = {\n",
    "                    'source':source,\n",
    "                    'target':target,\n",
    "                    'weight':weight       \n",
    "                }\n",
    "                graph['links'].append(link_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This graph has 24666 nodes and 313120 links.\n"
     ]
    }
   ],
   "source": [
    "nn = len(graph['nodes'])\n",
    "ne = len(graph['links'])\n",
    "print( f\"This graph has {nn} nodes and {ne} links.\")\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#weights=[]\n",
    "#for link in graph['links']:\n",
    "#    weights.append(link['weight'])\n",
    "#print(sum(weights))\n",
    "\n",
    "#plt.hist(weights, bins=25)\n",
    "#plt.title(\"Distribution of Weights\")\n",
    "#plt.xlabel(\"Wert\")\n",
    "#plt.ylabel(\"Häufigkeit\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's too much.\n",
    "\n",
    "#newlinks = []\n",
    "#for link in graph['links']:\n",
    "#    if link['weight'] > 0.3:\n",
    "#        newlinks.append(link)\n",
    "#graph['links'] = newlinks \n",
    "#len(graph['links'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The graph has {len(graph[\"links\"])} links.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Information about relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24666it [02:02, 200.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for count,node in tqdm.tqdm(enumerate(graph['nodes'])):\n",
    "    vec_numbers = np.array(mm.getrow(count).toarray()[0])\n",
    "    #maxWX = np.argmax(vec_numbers)\n",
    "    #hilf.update({'vec_numbers': vec_numbers})\n",
    "    msw = list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(np.argmax(vec_numbers))]\n",
    "    #hilf.update({'maxTFIDF': msw})\n",
    "    node.update({'msw' : msw})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24666/24666 [00:00<00:00, 346954.75it/s]\n",
      " 33%|███▎      | 102383/313120 [00:00<00:00, 503200.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313120/313120 [00:00<00:00, 508066.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links done\n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graphforgephi = nx.Graph()\n",
    "for node in tqdm.tqdm(graph['nodes']):\n",
    "    graphforgephi.add_node(node['id'],name = node['name'],date = node['date'],discussion_title = node['discussion_title'],party = node['party'], length = node['length'],msw = node['msw']);\n",
    "print('nodes done')\n",
    "for link in tqdm.tqdm(graph['links']):   \n",
    "    graphforgephi.add_edge(link['source'],link['target'],weight = link['weight'])\n",
    "print('links done')   \n",
    "nx.write_gexf(graphforgephi, \"../private/graphforgephi.gexf\")\n",
    "print('save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate word networks enriched with party information\n",
    "\n",
    "Import the basic stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/speeches_preprocessed.json', 'r') as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reden = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step of data cleaning can be skipped soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean party labels\n",
    "for rede in reden:\n",
    "    rede['party']=rede['party'].replace(u'\\xa0', u' ')\n",
    "    if rede['party']=='Bündnis 90/Die Grünen':\n",
    "        rede['party']='BÜNDNIS 90/DIE GRÜNEN'\n",
    "    if rede['party']=='Fraktionslos':\n",
    "        rede['party']='fraktionslos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection\n",
    "\n",
    "Now select, if desired, a subset of speeches by party, parlamentarians, date, etc. Note that it does not work for the 'text'-field, but 'text_lem' should work.\n",
    "\n",
    "To be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(reden[0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_for(what, search_terms, speeches):\n",
    "    filtered_speeches = []\n",
    "    for speech in speeches:\n",
    "        if ( speech[what] in set(search_terms) ):\n",
    "            filtered_speeches.append(speech)\n",
    "    filtered_speeches.sort(key = lambda x:x['date']) \n",
    "    return filtered_speeches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = ['Hansjörg Durz','Birke Bull-Bischoff','Stefan Kaufmann','Ernst Dieter Rossmann','Götz Frömming','Katja Suding','Kai Gehring','Tankred Schipanski','Saskia Esken','Oliver Kaczmarek','Nicola Beer','Anke Domscheit-Berg','Tabea Rößner','Manuel Höferlin','Sven Lehmann','Karamba Diaby','Susann Rüthrich','Katarina Barley','Sylvia Pantel','Johannes Huber','Katrin Werner','Grigorios Aggelidis','Katja Dörner','Martin Reichardt','Nadine Schön','Nicole Höchst','Stefan Schwartze','Norbert Müller','Uwe Schulz','Maik Beermann','Josephine Ortleb','Cornelia Möhring','Ulle Schauws','Silke Launert','Wiebke Esdar','Gülistan Yüksel','Matthias Seestern-Pauly','Marcus Weinberg','Martin Patzelt','Dagmar Schmidt','Anna Christmann','Uwe Kamann','Silvia Breher','Nicole Bauer','Leni Breymaier','Katrin Helling-Plahr','Annalena Baerbock','Petra Sitte','Mariana Iris Harder-Kühnel','Katja Mast','Roman Müller-Böhm','Doris Achelwilm','Yvonne Magwas','Sönke Rix','Ronja Kemmer','Margit Stumpp','Manja Schüle','Jens Brandenburg','Nicole Gohlke','Katrin Staffler','Beate Walter-Rosenheimer','Bettina Margarethe Wiesmann','Ulrike Bahr','Franziska Giffey','Anja Karliczek','Michaela Noll','Yasmin Fahimi','Melanie Bernstein','Stephan Albani','Marja-Liisa Völlers','Thomas Sattelberger','Dietlind Tiemann','René Röspel','Albert Rupprecht','Michael Espendiller','Joana Cotar','Mario Brandenburg','Volker Münz','Astrid Mannes','Ekin Deligöz','Stefan Sauer','Svenja Stadler','Swen Schulz','Kerstin Radomski','Johannes Steiniger','Caren Marks','Andreas Steier','Dieter Janecek','Sybille Benning','Thomas Rachel','Dorothee Bär','Frank Pasemann','Lars Klingbeil','Ingrid Pahlmann','Markus Paschke','Elvan Korkmaz-Emre','Charlotte Schneidewind-Hartnagel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reden_selection = filter_for('name', members, reden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3149"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reden = reden_selection\n",
    "len(reden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build corpus and count word frequencies per party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3149/3149 [00:00<00:00, 10490.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3149"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "allwords = []\n",
    "\n",
    "# prepare for per party counts\n",
    "allwordsperparty = {\n",
    "    'SPD':[],\n",
    "    'FDP':[],\n",
    "    'CDU/CSU':[],\n",
    "    'DIE LINKE':[],\n",
    "    'BÜNDNIS 90/DIE GRÜNEN':[],\n",
    "    'AfD':[],\n",
    "    'fraktionslos':[],\n",
    "    'Bremen':[]   \n",
    "}\n",
    "        \n",
    "#consider = ['PROPN']\n",
    "#consider = ['ADJ']\n",
    "consider = ['NOUN']\n",
    "for rede in tqdm.tqdm(reden):\n",
    "    #if(len(rede['text']) > 1000):\n",
    "    #rel_lemmata = [ ele for ex,ele in enumerate(rede['text_lem']) if (rede['text_pos'][ex] in consider and len(ele) > 7 and len(ele) < 16)]\n",
    "    rel_lemmata = [ ele for ex,ele in enumerate(rede['text_lem']) if rede['text_pos'][ex] in consider ]\n",
    "    allwords.extend(rel_lemmata)\n",
    "    allwordsperparty[rede['party']].extend(rel_lemmata)\n",
    "    corpus.append( \" \".join(rel_lemmata ))\n",
    "   \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select words by frequency in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features02=[]\n",
    "#word_counter= Counter(x for xs in corpus for x in xs)\n",
    "word_counter = Counter(allwords)\n",
    "for word in word_counter.keys():\n",
    "    if word_counter[word] > 20 and word_counter[word] < 1000:\n",
    "        features02.append(word)\n",
    "\n",
    "#print(word_counter)\n",
    "#Counter(corpus)\n",
    "len(features02)\n",
    "#word_counter['Arzt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select words by TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_selection = []\n",
    "for party in allwordsperparty.keys():\n",
    "    corpus_selection.append(\" \".join(allwordsperparty[party] ))\n",
    "    \n",
    "#print(corpus_selection[0][0:10])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now consider 14383 different words.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3149, 14383)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizer_selection = CountVectorizer(vocabulary = features02, decode_error='ignore' , lowercase=False, ngram_range=(1, 1))\n",
    "vectorizer_selection = CountVectorizer(decode_error='ignore' , lowercase=False , max_df=0.8, min_df=2, ngram_range=(1, 1))\n",
    "\n",
    "mm_selection = vectorizer_selection.fit_transform(corpus)\n",
    "featuresforselection = vectorizer_selection.get_feature_names()\n",
    "\n",
    "print(f'We now consider {len(featuresforselection)} different words.')\n",
    "mm_selection.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    \n",
    "vectorizer_selection = TfidfVectorizer(lowercase=False,max_df=0.8, min_df=2/len(corpus_selection))\n",
    "mm_selection  = vectorizer_selection.fit_transform(corpus_selection)\n",
    "featuresforselection = vectorizer_selection.get_feature_names()\n",
    "mm_selection.get_shape()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1537"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmax = 3\n",
    "features02 = []\n",
    "for rx,rede in enumerate(range(mm_selection.get_shape()[0])):\n",
    "    vec = np.array(mm_selection.getrow(rx).toarray()[0])\n",
    "    ind = np.argpartition(vec, -nmax)[-nmax:]\n",
    "    #print([vec[ix] for ix in ind])\n",
    "    #print([featuresforselection[ix] for ix in ind])\n",
    "    features02.extend([featuresforselection[ix] for ix in ind])\n",
    "features02 = set(features02)\n",
    "len(features02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if 'Arzt' in features02:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count word frequencies per speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now consider 1537 different words.\n"
     ]
    }
   ],
   "source": [
    "#vectorizer01 = CountVectorizer( decode_error='ignore' , lowercase=False , max_df=0.3, min_df=2/len(corpus),max_features=1000)\n",
    "#vectorizer01 = CountVectorizer( decode_error='ignore' , lowercase=False , max_df=0.3, min_df=2, ngram_range=(1, 1))\n",
    "\n",
    "vectorizer01 = CountVectorizer(vocabulary = features02, decode_error='ignore' , lowercase=False, ngram_range=(1, 1))\n",
    "#vectorizer01 = CountVectorizer(decode_error='ignore' , lowercase=False , max_df=0.6, min_df=0.01, ngram_range=(1, 1))\n",
    "\n",
    "\n",
    "X01 = vectorizer01.fit_transform(corpus)\n",
    "features01 = vectorizer01.get_feature_names()\n",
    "\n",
    "print(f'We now consider {len(features01)} different words.')\n",
    "#print(features01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(features01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1537, 3149)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X01T = X01.T\n",
    "X01T.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "SIMT01 = cosine_similarity(X01T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1537, 1537)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMT01.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count words per party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_party = {}\n",
    "\n",
    "for party in allwordsperparty.keys():\n",
    "    counts_per_party.update({ party : Counter(allwordsperparty[party])  })\n",
    "\n",
    "#counts_per_party = {\n",
    "#    'SPD': Counter(allwordsperparty['SPD']),\n",
    "#    'FDP':Counter(allwordsperparty['FDP']),\n",
    "#    'CDU/CSU':[],\n",
    "#    'DIE LINKE':[],\n",
    "#    'BÜNDNIS 90/DIE GRÜNEN':[],\n",
    "#    'AfD':[],\n",
    "#    'fraktionslos':[],\n",
    "#    'Bremen':[]   \n",
    "#}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for wx,word in enumerate(features01):\n",
    "    node = {\n",
    "        'id' : wx,\n",
    "        'name' : word,\n",
    "        'cALL' : word_counter[word]/len(word_counter),\n",
    "        'cSPD' : counts_per_party['SPD'][word]/len(counts_per_party['SPD']),\n",
    "        'cFDP' : counts_per_party['FDP'][word]/len(counts_per_party['FDP']),\n",
    "        'cCDU' : counts_per_party['CDU/CSU'][word]/len(counts_per_party['CDU/CSU']),\n",
    "        'cLINKE' : counts_per_party['DIE LINKE'][word]/len(counts_per_party['DIE LINKE']),\n",
    "        'cGRUENE' : counts_per_party['BÜNDNIS 90/DIE GRÜNEN'][word]/len(counts_per_party['BÜNDNIS 90/DIE GRÜNEN']),\n",
    "        'cAFD' : counts_per_party['AfD'][word]/len(counts_per_party['AfD'])\n",
    "    }\n",
    "    nodes.append(node)\n",
    "    \n",
    "\n",
    "graph = {\n",
    "    'directed': False,\n",
    "    'graph': 'word_graph',\n",
    "    'links': [],\n",
    "    'nodes': nodes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1537it [00:00, 1743.85it/s]\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "\n",
    "min_weight = 0.15\n",
    "for ix,nodeI in tqdm.tqdm(enumerate(graph['nodes'])):\n",
    "    for jx,nodeJ in enumerate(graph['nodes']):\n",
    "        if nodeI['id'] < nodeJ['id']:          \n",
    "            source = nodeI['id']\n",
    "            target = nodeJ['id']\n",
    "            weight = SIMT01[ix,jx]\n",
    "            if weight > min_weight:\n",
    "                #links.append([source,target,weight])\n",
    "                link_dict = {\n",
    "                    'source':source,\n",
    "                    'target':target,\n",
    "                    'weight':weight       \n",
    "                }\n",
    "                graph['links'].append(link_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This graph has 1537 nodes and 12176 links.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn = len(graph['nodes'])\n",
    "ne = len(graph['links'])\n",
    "print( f\"This graph has {nn} nodes and {ne} links.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "weights=[]\n",
    "for link in graph['links']:\n",
    "    weights.append(link['weight'])\n",
    "#print(sum(weights))\n",
    "\n",
    "plt.hist(weights, bins=25)\n",
    "plt.title(\"Distribution of Weights\")\n",
    "plt.xlabel(\"Wert\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph has 37177 links.\n"
     ]
    }
   ],
   "source": [
    "print(f'The graph has {len(graph[\"links\"])} links.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1537/1537 [00:00<00:00, 2604.28it/s]\n",
      "100%|██████████| 12176/12176 [00:00<00:00, 463336.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes done\n",
      "links done\n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graphforgephi = nx.Graph()\n",
    "for node in tqdm.tqdm(graph['nodes']):\n",
    "    graphforgephi.add_node(node['id'],name = node['name'],cALL = node['cALL'],cSPD = node['cSPD'],cFDP = node['cFDP'],cCDU = node['cCDU'],cLINKE = node['cLINKE'],cGRUENE = node['cGRUENE'], cAFD = node['cAFD'] );\n",
    "    #if(node['name'] == 'Angela Merkel'):\n",
    "    #    print(node['tops'])\n",
    "\n",
    "print('nodes done')\n",
    "for link in tqdm.tqdm(graph['links']):   \n",
    "    graphforgephi.add_edge(link['source'],link['target'],weight = link['weight'])\n",
    "print('links done')   \n",
    "nx.write_gexf(graphforgephi, \"../private/graphforgephi.gexf\")\n",
    "print('save done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Explorations\n",
    "\n",
    "## Correlation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "data = normalize(X01T,norm='l2',axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.corrcoef(data.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.nan_to_num(C, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "C_r = pca.fit(C).transform(C)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print(\n",
    "    \"explained variance ratio (first two components): %s\"\n",
    "    % str(pca.explained_variance_ratio_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "colors = [\"navy\", \"turquoise\", \"darkorange\"]\n",
    "lw = 2\n",
    "plt.scatter(C_r[:,0], C_r[:, 1],s=1, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.3, min_df=2/len(corpus),norm='l2')\n",
    "tf_idf_matrix  = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Tranform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurevec = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "parties = []\n",
    "\n",
    "for rede in reden:\n",
    "    if rede['name'] not in names:\n",
    "        names.append(rede['name'])\n",
    "        parties.append(rede['party'])\n",
    "        \n",
    "parlamentarier = []\n",
    "\n",
    "for count,name in tqdm.tqdm(enumerate(names)):\n",
    "    hilf = {\n",
    "        'id':count+1,\n",
    "        'name': names[count],\n",
    "        'party': parties[count]\n",
    "    }\n",
    "    \n",
    "    text_lem = []\n",
    "    for rede in reden:\n",
    "        if rede['name'] == name:\n",
    "            rel_lemmata = [ ele.lower() for ex,ele in enumerate(rede['text_lem']) if ele.lower() in featurevec  ]\n",
    "            text_lem.extend(rel_lemmata)\n",
    "\n",
    "    hilf.update({'text_lem': text_lem})\n",
    "\n",
    "    parlamentarier.append(hilf)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(parlamentarier[0]['text_lem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mentionedby = {}\n",
    "for wort in featurevec:\n",
    "    #print(wort)\n",
    "    mentionedby.update({ wort : [] })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'kollegin' in featurevec:\n",
    "    print('ja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parla in parlamentarier:\n",
    "    for wort in parla['text_lem']: \n",
    "        mentionedby[wort].append(parla['name']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n",
    "corpus2=[  mentionedby[wort] for wort in mentionedby   ]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(vocabulary=featurevec,norm='l2')\n",
    "tf_idf_matrix2  = vectorizer2.fit_transform(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_similarity = tf_idf_matrix2.T * tf_idf_matrix2\n",
    "#pairwise_similarity = tf_idf_matrix * tf_idf_matrix.T\n",
    "print(len(pairwise_similarity.toarray()))\n",
    "similarity = pairwise_similarity.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "featurevec = vectorizer.get_feature_names()\n",
    "for wx,word in enumerate(featurevec):\n",
    "    node = {\n",
    "        'id' : wx,\n",
    "        'name' : word\n",
    "    }\n",
    "    nodes.append(node)\n",
    "    \n",
    "\n",
    "graph = {\n",
    "    'directed': False,\n",
    "    'graph': 'cooccurr_graph',\n",
    "    'links': [],\n",
    "    'nodes': nodes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_weight = 0.5\n",
    "for ix,nodeI in tqdm.tqdm(enumerate(graph['nodes'])):\n",
    "    for jx,nodeJ in enumerate(graph['nodes']):\n",
    "        if nodeI['id'] < nodeJ['id']:\n",
    "            source = nodeI['id']\n",
    "            target = nodeJ['id']\n",
    "            weight = similarity[ix,jx]\n",
    "            if weight > min_weight:\n",
    "                link_dict = {\n",
    "                    'source':source,\n",
    "                    'target':target,\n",
    "                    'weight':weight       \n",
    "                }\n",
    "                graph['links'].append(link_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graphforgephi = nx.Graph()\n",
    "for node in tqdm.tqdm(graph['nodes']):\n",
    "    graphforgephi.add_node(node['id'],name = node['name']);\n",
    "    #if(node['name'] == 'Angela Merkel'):\n",
    "    #    print(node['tops'])\n",
    "\n",
    "print('nodes done')\n",
    "for link in tqdm.tqdm(graph['links']):   \n",
    "    graphforgephi.add_edge(link['source'],link['target'],weight = link['weight'])\n",
    "print('links done')   \n",
    "nx.write_gexf(graphforgephi, \"graphforgephi.gexf\")\n",
    "print('save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
